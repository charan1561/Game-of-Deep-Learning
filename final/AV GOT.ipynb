{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] ='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "with open(\"X_train1.npy\",\"rb\") as fp:\n",
    "    X = np.load(fp)\n",
    "with open(\"y_train1.npy\",\"rb\") as fp:\n",
    "    y = np.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_models(img_rows, img_cols, channel=1, num_classes=None):\n",
    "#     model = applications.resnet50.ResNet50(include_top=True, weights='imagenet')\n",
    "    model = applications.inception_resnet_v2.InceptionResNetV2(include_top=True, weights='imagenet')\n",
    "    # Truncate and replace softmax layer for transfer learning\n",
    "    \n",
    "    model.layers.pop()\n",
    "    model.outputs = [model.layers[-1].output]\n",
    "    model.layers[-1].outbound_nodes = []\n",
    "    \n",
    "    new_model = Sequential()\n",
    "    new_model.add(model)\n",
    "    new_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#     Uncomment below to set the first 10 layers to non-trainable (weights will not be updated)\n",
    "    for layer in model.layers[:5]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Learning rate is changed to 0.001\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    new_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def res_models(img_rows, img_cols, channel=1, num_classes=None):\n",
    "#     model = applications.resnet50.ResNet50(include_top=True, weights='imagenet')\n",
    "\n",
    "#     # Truncate and replace softmax layer for transfer learning\n",
    "    \n",
    "#     model.layers.pop()\n",
    "#     model.outputs = [model.layers[-1].output]\n",
    "#     model.layers[-1].outbound_nodes = []\n",
    "    \n",
    "#     new_model = Sequential()\n",
    "#     new_model.add(model)\n",
    "#     new_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# #     Uncomment below to set the first 10 layers to non-trainable (weights will not be updated)\n",
    "#     for layer in model.layers[:5]:\n",
    "#         layer.trainable = True\n",
    "\n",
    "#     # Learning rate is changed to 0.001\n",
    "#     adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "#     sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#     new_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 299, 299 # Resolution of inputs\n",
    "channel = 1\n",
    "num_classes = 6\n",
    "batch_size = 1\n",
    "nb_epoch = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inc_models(img_rows, img_cols, channel, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x7f89a6a272e8> True\n",
      "<keras.layers.core.Dense object at 0x7f89a3b107b8> True\n"
     ]
    }
   ],
   "source": [
    "for i in model.layers:\n",
    "    print(i,i.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_resnet_v2 (Model)  multiple                  54336736  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 9222      \n",
      "=================================================================\n",
      "Total params: 54,345,958\n",
      "Trainable params: 54,285,414\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/humonics/.virtualenvs/capi/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5626 samples, validate on 626 samples\n",
      "Epoch 1/12\n",
      "5626/5626 [==============================] - 136s 24ms/step - loss: 0.7749 - acc: 0.7138 - val_loss: 0.3158 - val_acc: 0.8754\n",
      "Epoch 2/12\n",
      "5626/5626 [==============================] - 121s 22ms/step - loss: 0.2490 - acc: 0.9118 - val_loss: 0.2556 - val_acc: 0.9153\n",
      "Epoch 3/12\n",
      "5626/5626 [==============================] - 120s 21ms/step - loss: 0.1295 - acc: 0.9586 - val_loss: 0.1925 - val_acc: 0.9361\n",
      "Epoch 4/12\n",
      "5626/5626 [==============================] - 120s 21ms/step - loss: 0.0650 - acc: 0.9822 - val_loss: 0.2336 - val_acc: 0.9281\n",
      "Epoch 5/12\n",
      "5626/5626 [==============================] - 120s 21ms/step - loss: 0.0390 - acc: 0.9899 - val_loss: 0.2384 - val_acc: 0.9281\n",
      "Epoch 6/12\n",
      "5626/5626 [==============================] - 120s 21ms/step - loss: 0.0267 - acc: 0.9934 - val_loss: 0.2284 - val_acc: 0.9361\n",
      "Epoch 7/12\n",
      "5626/5626 [==============================] - 120s 21ms/step - loss: 0.0175 - acc: 0.9963 - val_loss: 0.2450 - val_acc: 0.9329\n",
      "Epoch 8/12\n",
      "5626/5626 [==============================] - 120s 21ms/step - loss: 0.0182 - acc: 0.9950 - val_loss: 0.2452 - val_acc: 0.9345\n",
      "Epoch 9/12\n",
      "5626/5626 [==============================] - 120s 21ms/step - loss: 0.0104 - acc: 0.9984 - val_loss: 0.2322 - val_acc: 0.9329\n",
      "Epoch 10/12\n",
      "5626/5626 [==============================] - 120s 21ms/step - loss: 0.0125 - acc: 0.9972 - val_loss: 0.2572 - val_acc: 0.9393\n",
      "Epoch 11/12\n",
      "5626/5626 [==============================] - 120s 21ms/step - loss: 0.0083 - acc: 0.9986 - val_loss: 0.2780 - val_acc: 0.9281\n",
      "Epoch 12/12\n",
      "5626/5626 [==============================] - 120s 21ms/step - loss: 0.0074 - acc: 0.9984 - val_loss: 0.2837 - val_acc: 0.9329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89a50e9908>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Fine-tuning\n",
    "model.fit(X, y,\n",
    "          nb_epoch=12,\n",
    "          shuffle=True,\n",
    "          verbose=1,\n",
    "          validation_split=0.1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved..!\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('inc1.hdf5')\n",
    "print(\"model saved..!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_resnet_v2 (Model)  multiple                  54336736  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 9222      \n",
      "=================================================================\n",
      "Total params: 54,345,958\n",
      "Trainable params: 54,285,414\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AVGOT2.ipynb         ResNet50.hdf5                    \u001b[0m\u001b[01;32mtrain.zip\u001b[0m*\r\n",
      "\u001b[01;32m'AV GOT.ipynb'\u001b[0m*       result1.csv                      Xn_train.npy\r\n",
      " my_model.h5          result2.csv                      X_train1.npy\r\n",
      " my_model.hdf5        \u001b[01;32msample_submission_ns2btKE.csv\u001b[0m*   \u001b[01;32mX_train.npy\u001b[0m*\r\n",
      " ResNet50_25c1.hdf5   \u001b[01;32mtest_ApKoW4T.csv\u001b[0m*                yn_train.npy\r\n",
      " ResNet50_25.hdf5     \u001b[34;42mtrain\u001b[0m/                           y_train1.npy\r\n",
      " ResNet50.h5          train1.h5                        \u001b[01;32my_train.npy\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_ApKoW4T.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2680/2680 [00:04<00:00, 566.58it/s]\n"
     ]
    }
   ],
   "source": [
    "test_image = []\n",
    "for i in tqdm(range(test.shape[0])):\n",
    "    img = image.load_img('train/images/'+test['image'][i], target_size=(299,299,1))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    test_image.append(img)\n",
    "test = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(feature.shape[0]):\n",
    "    pred = np.argmax(feature[i])\n",
    "    results.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2680"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_ApKoW4T.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('sample_submission_ns2btKE.csv')\n",
    "sample['image'] = test['image']\n",
    "sample['category'] = results\n",
    "sample.to_csv('result_inc.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AVGOT2.ipynb         result1.csv                      Xn_train.npy\r\n",
      "\u001b[0m\u001b[01;32m'AV GOT.ipynb'\u001b[0m*       result2.csv                      X_train1.npy\r\n",
      " my_model.h5          result3.csv                      \u001b[01;32mX_train.npy\u001b[0m*\r\n",
      " my_model.hdf5        \u001b[01;32msample_submission_ns2btKE.csv\u001b[0m*   yn_train.npy\r\n",
      " ResNet50_25c1.hdf5   \u001b[01;32mtest_ApKoW4T.csv\u001b[0m*                y_train1.npy\r\n",
      " ResNet50_25.hdf5     \u001b[34;42mtrain\u001b[0m/                           \u001b[01;32my_train.npy\u001b[0m*\r\n",
      " ResNet50.h5          train1.h5\r\n",
      " ResNet50.hdf5        \u001b[01;32mtrain.zip\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving to .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2823080.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2870024.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2662125.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2900420.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2804883.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image  category\n",
       "0  2823080.jpg         1\n",
       "1  2870024.jpg         1\n",
       "2  2662125.jpg         2\n",
       "3  2900420.jpg         3\n",
       "4  2804883.jpg         2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6252/6252 [00:09<00:00, 662.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# We have grayscale images, so while loading the images we will keep grayscale=True, if you have RGB images, you should set grayscale as False\n",
    "train_image = []\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    img = image.load_img('train/images/'+train['image'][i], target_size=(299,299,1))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    train_image.append(img)\n",
    "X = np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f X_train.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AVGOT2.ipynb       ResNet50.hdf5                    train1.h5\r\n",
      "\u001b[0m\u001b[01;32m'AV GOT.ipynb'\u001b[0m*     result1.csv                      \u001b[01;32mtrain.zip\u001b[0m*\r\n",
      " my_model.h5        result2.csv                      Xn_train.npy\r\n",
      " my_model.hdf5      \u001b[01;32msample_submission_ns2btKE.csv\u001b[0m*   \u001b[01;32mX_train.npy\u001b[0m*\r\n",
      " ResNet50_25.hdf5   \u001b[01;32mtest_ApKoW4T.csv\u001b[0m*                yn_train.npy\r\n",
      " ResNet50.h5        \u001b[34;42mtrain\u001b[0m/                           \u001b[01;32my_train.npy\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train1.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train['category'].values\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_train1.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data2/charan/api/AV/GOTDeepLearning'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AVGOT2.ipynb         result1.csv                      Xn_train.npy\r\n",
      "\u001b[0m\u001b[01;32m'AV GOT.ipynb'\u001b[0m*       result2.csv                      X_train1.npy\r\n",
      " my_model.h5          result3.csv                      \u001b[01;32mX_train.npy\u001b[0m*\r\n",
      " my_model.hdf5        \u001b[01;32msample_submission_ns2btKE.csv\u001b[0m*   yn_train.npy\r\n",
      " ResNet50_25c1.hdf5   \u001b[01;32mtest_ApKoW4T.csv\u001b[0m*                y_train1.npy\r\n",
      " ResNet50_25.hdf5     \u001b[34;42mtrain\u001b[0m/                           \u001b[01;32my_train.npy\u001b[0m*\r\n",
      " ResNet50.h5          train1.h5\r\n",
      " ResNet50.hdf5        \u001b[01;32mtrain.zip\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6252"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train) #.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "list2 = []\n",
    "list3 = []\n",
    "list4 = []\n",
    "list5 = []\n",
    "for i in range(len(train['category'])):\n",
    "    if train['category'][i] == 1:\n",
    "        list1.append(train['image'][i])\n",
    "    elif train['category'][i] == 2:\n",
    "        list2.append(train['image'][i])\n",
    "    elif train['category'][i] == 3:\n",
    "        list3.append(train['image'][i])\n",
    "    elif train['category'][i] == 4:\n",
    "        list4.append(train['image'][i])\n",
    "    else:\n",
    "        list5.append(train['image'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6252"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list1) + len(list2) + len(list3) + len(list4) + len(list5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1167"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "916"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = '/data2/charan/api/AV/GOTDeepLearning/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jpgfile in glob.iglob(os.path.join(src_dir, list)):\n",
    "    shutil.copy(pngfile, dst_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
